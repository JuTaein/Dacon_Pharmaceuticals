{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXvP3W2gNBZp"
      },
      "source": [
        "#Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bIlydzVMMms",
        "outputId": "60476924-632f-4164-828a-cd1b4163c4f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sf4HXieTMQhq",
        "outputId": "fa041f41-1394-4f63-c98b-6ca2d5a4f7e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import StackingRegressor, VotingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from google.colab import files\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "path = '/content/drive/MyDrive/dacon_1/input_10.csv'\n",
        "train = pd.read_csv(path)\n"
      ],
      "metadata": {
        "id": "dTe9eVARoRiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "features_with_nan = train.columns[train.isna().any()].tolist()\n",
        "if features_with_nan:\n",
        "    print(f\"\\n[NaN 값을 포함하는 피처(열) 이름]: {features_with_nan}\")\n",
        "else:\n",
        "    print(\"\\nDataFrame에 NaN 값을 포함하는 피처(열)가 없습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4bk2laXlNfs",
        "outputId": "684512dc-da92-4123-8286-8a7416f60e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[NaN 값을 포함하는 피처(열) 이름]: ['SpherocityIndex', 'SASA', 'MolVolume']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "columns_to_drop = [\n",
        "    'SpherocityIndex', 'SASA', 'MolVolume'\n",
        "    ]\n",
        "\n",
        "existing_features_to_remove = [col for col in columns_to_drop if col in train.columns]\n",
        "\n",
        "if existing_features_to_remove:\n",
        "    train = train.drop(columns=existing_features_to_remove)\n",
        "    print(f\"train.shape: {train.shape}\")\n",
        "\n",
        "print(\"\\ntrain head:\")\n",
        "print(train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmEzNwpGgIMx",
        "outputId": "bd1bbeb9-086b-4a47-d0f4-f5c900666766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.shape: (1681, 1318)\n",
            "\n",
            "train head:\n",
            "           ID         PMI1         PMI2          PMI3      NPR1      NPR2  \\\n",
            "0  TRAIN_0000   575.069242  2555.122302   2920.656196  0.196897  0.874845   \n",
            "1  TRAIN_0001   456.829070  1469.302773   1912.906155  0.238814  0.768100   \n",
            "2  TRAIN_0002   953.401111  2584.031148   3261.716948  0.292300  0.792230   \n",
            "3  TRAIN_0003  1996.471896  9465.097548  10133.290487  0.197021  0.934060   \n",
            "4  TRAIN_0004  1884.272386  2887.023659   4234.712130  0.444959  0.681752   \n",
            "\n",
            "   SlogP_VSA1  SlogP_VSA2  SlogP_VSA3  SlogP_VSA4  ...  sulfone  thioether  \\\n",
            "0    5.309813   26.307476    6.372925    0.000000  ...        0          0   \n",
            "1    4.736863   11.542964    6.372925    0.000000  ...        0          0   \n",
            "2    0.000000   29.335040    4.837589   15.931539  ...        0          0   \n",
            "3   10.046676   46.879761   11.295848    5.817221  ...        0          0   \n",
            "4    5.428790   21.153071   10.799569    5.893958  ...        0          0   \n",
            "\n",
            "   alkene  alkyne  halide  aniline  phosphate_ester  carboxylate  sulfonate  \\\n",
            "0       0       0       1        0                0            0          0   \n",
            "1       0       0       1        0                0            0          0   \n",
            "2       0       0       1        0                0            0          0   \n",
            "3       0       0       1        0                0            0          0   \n",
            "4       0       0       1        0                0            0          0   \n",
            "\n",
            "   quaternary_N  \n",
            "0             0  \n",
            "1             0  \n",
            "2             0  \n",
            "3             0  \n",
            "4             0  \n",
            "\n",
            "[5 rows x 1318 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop(columns=['Inhibition','ID'])\n",
        "y = train['Inhibition']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.1, random_state=42)\n",
        "import re\n",
        "X_train.columns = [re.sub('[^0-9a-zA-Z_]+', '_', str(col)) for col in X_train.columns]"
      ],
      "metadata": {
        "id": "ZlllBdUuod5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAMfm6kdNDsu"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    \"LightGBM\": LGBMRegressor(n_estimators=100, random_state=42),\n",
        "    \"NeuralNet\": MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42),\n",
        "    \"AdaBoost\": AdaBoostRegressor(n_estimators=100, random_state=42),\n",
        "    \"GradientBoost\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n",
        "    \"CatBoost\" : CatBoostRegressor(verbose=0, random_state=42)\n",
        "}\n",
        "\n",
        "model_sample = { }\n",
        "\n",
        "meta_model = Ridge(alpha = 1.0)\n",
        "\n",
        "models[\"Voting\"] = VotingRegressor(\n",
        "    estimators=[\n",
        "        ('rf', models[\"RandomForest\"]),\n",
        "        ('ada', models[\"AdaBoost\"]),\n",
        "        ('cat', models[\"CatBoost\"])\n",
        "    ],\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "models[\"Stacking\"] = StackingRegressor(\n",
        "    estimators=[\n",
        "        ('rf', models[\"RandomForest\"]),\n",
        "        ('ada', models[\"AdaBoost\"]),\n",
        "        ('cat', models[\"CatBoost\"]),\n",
        "    ],\n",
        "    final_estimator=meta_model,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    passthrough=False\n",
        ")"
      ],
      "metadata": {
        "id": "EHtznaE1TxL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yxMHdtUhROHn",
        "outputId": "f9131a1a-312b-4b0e-c084-e3aa9671fe9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== RandomForest ===\n",
            "Fold 1 | A (norm_rmse): 0.2370 | B (pearson): 0.4309 | Score: 0.5970\n",
            "Fold 2 | A (norm_rmse): 0.2624 | B (pearson): 0.3937 | Score: 0.5657\n",
            "Fold 3 | A (norm_rmse): 0.2438 | B (pearson): 0.4246 | Score: 0.5904\n",
            "Fold 4 | A (norm_rmse): 0.2556 | B (pearson): 0.3681 | Score: 0.5563\n",
            "Fold 5 | A (norm_rmse): 0.2431 | B (pearson): 0.4178 | Score: 0.5873\n",
            ">>> RandomForest 평균 | A: 0.2484 | B: 0.4070 | Score: 0.5793\n",
            "\n",
            "=== LightGBM ===\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010955 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 11981\n",
            "[LightGBM] [Info] Number of data points in the train set: 1209, number of used features: 906\n",
            "[LightGBM] [Info] Start training from score 33.364207\n",
            "Fold 1 | A (norm_rmse): 0.2428 | B (pearson): 0.4070 | Score: 0.5821\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010374 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 12008\n",
            "[LightGBM] [Info] Number of data points in the train set: 1209, number of used features: 910\n",
            "[LightGBM] [Info] Start training from score 32.526536\n",
            "Fold 2 | A (norm_rmse): 0.2629 | B (pearson): 0.3996 | Score: 0.5683\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010084 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 11955\n",
            "[LightGBM] [Info] Number of data points in the train set: 1210, number of used features: 910\n",
            "[LightGBM] [Info] Start training from score 33.080778\n",
            "Fold 3 | A (norm_rmse): 0.2481 | B (pearson): 0.4118 | Score: 0.5819\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010299 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 11990\n",
            "[LightGBM] [Info] Number of data points in the train set: 1210, number of used features: 901\n",
            "[LightGBM] [Info] Start training from score 33.111930\n",
            "Fold 4 | A (norm_rmse): 0.2551 | B (pearson): 0.3962 | Score: 0.5705\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010170 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 11957\n",
            "[LightGBM] [Info] Number of data points in the train set: 1210, number of used features: 898\n",
            "[LightGBM] [Info] Start training from score 33.757308\n",
            "Fold 5 | A (norm_rmse): 0.2520 | B (pearson): 0.4104 | Score: 0.5792\n",
            ">>> LightGBM 평균 | A: 0.2522 | B: 0.4050 | Score: 0.5764\n",
            "\n",
            "=== NeuralNet ===\n",
            "Fold 1 | A (norm_rmse): 0.3351 | B (pearson): 0.1744 | Score: 0.4197\n",
            "Fold 2 | A (norm_rmse): 0.2770 | B (pearson): 0.3386 | Score: 0.5308\n",
            "Fold 3 | A (norm_rmse): 0.2428 | B (pearson): 0.4631 | Score: 0.6102\n",
            "Fold 4 | A (norm_rmse): 0.2593 | B (pearson): 0.3340 | Score: 0.5373\n",
            "Fold 5 | A (norm_rmse): 0.2746 | B (pearson): 0.2838 | Score: 0.5046\n",
            ">>> NeuralNet 평균 | A: 0.2778 | B: 0.3188 | Score: 0.5205\n",
            "\n",
            "=== AdaBoost ===\n",
            "Fold 1 | A (norm_rmse): 0.2492 | B (pearson): 0.4161 | Score: 0.5835\n",
            "Fold 2 | A (norm_rmse): 0.2603 | B (pearson): 0.3993 | Score: 0.5695\n",
            "Fold 3 | A (norm_rmse): 0.2538 | B (pearson): 0.4571 | Score: 0.6016\n",
            "Fold 4 | A (norm_rmse): 0.2629 | B (pearson): 0.3738 | Score: 0.5555\n",
            "Fold 5 | A (norm_rmse): 0.2525 | B (pearson): 0.3939 | Score: 0.5707\n",
            ">>> AdaBoost 평균 | A: 0.2557 | B: 0.4080 | Score: 0.5762\n",
            "\n",
            "=== GradientBoost ===\n",
            "Fold 1 | A (norm_rmse): 0.2438 | B (pearson): 0.3850 | Score: 0.5706\n",
            "Fold 2 | A (norm_rmse): 0.2573 | B (pearson): 0.4274 | Score: 0.5850\n",
            "Fold 3 | A (norm_rmse): 0.2438 | B (pearson): 0.4262 | Score: 0.5912\n",
            "Fold 4 | A (norm_rmse): 0.2504 | B (pearson): 0.4093 | Score: 0.5794\n",
            "Fold 5 | A (norm_rmse): 0.2439 | B (pearson): 0.4141 | Score: 0.5851\n",
            ">>> GradientBoost 평균 | A: 0.2479 | B: 0.4124 | Score: 0.5823\n",
            "\n",
            "=== XGBoost ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [12:12:48] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 | A (norm_rmse): 0.2552 | B (pearson): 0.3485 | Score: 0.5466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [12:12:51] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 | A (norm_rmse): 0.2745 | B (pearson): 0.3520 | Score: 0.5388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [12:12:55] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 | A (norm_rmse): 0.2532 | B (pearson): 0.4054 | Score: 0.5761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [12:12:57] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 | A (norm_rmse): 0.2648 | B (pearson): 0.3459 | Score: 0.5406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [12:13:00] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 | A (norm_rmse): 0.2622 | B (pearson): 0.3556 | Score: 0.5467\n",
            ">>> XGBoost 평균 | A: 0.2620 | B: 0.3615 | Score: 0.5498\n",
            "\n",
            "=== CatBoost ===\n",
            "Fold 1 | A (norm_rmse): 0.2449 | B (pearson): 0.3855 | Score: 0.5703\n",
            "Fold 2 | A (norm_rmse): 0.2585 | B (pearson): 0.4234 | Score: 0.5824\n",
            "Fold 3 | A (norm_rmse): 0.2410 | B (pearson): 0.4468 | Score: 0.6029\n",
            "Fold 4 | A (norm_rmse): 0.2533 | B (pearson): 0.3939 | Score: 0.5703\n",
            "Fold 5 | A (norm_rmse): 0.2457 | B (pearson): 0.4165 | Score: 0.5854\n",
            ">>> CatBoost 평균 | A: 0.2487 | B: 0.4132 | Score: 0.5823\n",
            "\n",
            "=== Voting ===\n",
            "Fold 1 | A (norm_rmse): 0.2378 | B (pearson): 0.4358 | Score: 0.5990\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-14-3217883745.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mnorm_rmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpearson_corr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sample_weight\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     ]\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    101\u001b[0m             delayed(_fit_single_estimator)(\n\u001b[1;32m    102\u001b[0m                 \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def scoring(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    y_range = y_true.max() - y_true.min()\n",
        "    norm_rmse = rmse / y_range if y_range != 0 else 0  # 방어\n",
        "    pearson_corr = pearsonr(y_true, y_pred)[0]\n",
        "    score = 0.5 * (1 - min(norm_rmse, 1)) + 0.5 * pearson_corr\n",
        "    return norm_rmse, pearson_corr, score\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    fold_results = []\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_train), 1):\n",
        "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_val)\n",
        "        norm_rmse, pearson_corr, score = scoring(y_val, y_pred)\n",
        "        fold_results.append((norm_rmse, pearson_corr, score))\n",
        "        print(f\"Fold {fold} | A (norm_rmse): {norm_rmse:.4f} | B (pearson): {pearson_corr:.4f} | Score: {score:.4f}\")\n",
        "    avg_A = np.mean([fr[0] for fr in fold_results])\n",
        "    avg_B = np.mean([fr[1] for fr in fold_results])\n",
        "    avg_score = np.mean([fr[2] for fr in fold_results])\n",
        "    cv_results[name] = {'A_norm_rmse_mean': avg_A, 'B_pearson_mean': avg_B, 'Score_mean': avg_score}\n",
        "    print(f\">>> {name} 평균 | A: {avg_A:.4f} | B: {avg_B:.4f} | Score: {avg_score:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/dacon_1/'\n",
        "output_filename = 'candidates_03_1_new.csv'\n",
        "output_path = os.path.join(base_dir, output_filename)\n",
        "\n",
        "try:\n",
        "    train.to_csv(output_path, index=False)\n",
        "    print(f\"\\n'{output_filename}' 파일이 '{output_path}'에 성공적으로 저장되었습니다.\")\n",
        "    # 저장된 파일이 실제로 존재하는지 확인 (선택 사항)\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"파일 존재 확인: {output_path}\")\n",
        "    else:\n",
        "        print(f\"오류: 파일 저장 후 존재 여부 확인 실패: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yWkuz8tNq8b",
        "outputId": "641a046c-6dc9-47ea-c10c-34cbe9bf41e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'candidates_03_1_new.csv' 파일이 '/content/drive/MyDrive/dacon_1/candidates_03_1_new.csv'에 성공적으로 저장되었습니다.\n",
            "파일 존재 확인: /content/drive/MyDrive/dacon_1/candidates_03_1_new.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/dacon_1/03_1_test.csv'\n",
        "test = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "lYOaUMK6OyPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "columns_to_drop = [\n",
        "    'MaxPartialCharge', 'MinPartialCharge'\n",
        "    ]\n",
        "\n",
        "existing_features_to_remove = [col for col in columns_to_drop if col in test.columns]\n",
        "\n",
        "if existing_features_to_remove:\n",
        "    test = test.drop(columns=existing_features_to_remove)\n",
        "    print(f\"train.shape: {test.shape}\")\n",
        "\n",
        "print(\"\\ntrain head:\")\n",
        "print(test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAcQYAeOO0Hj",
        "outputId": "596df5b6-940e-4030-e7c6-6517ad3e3ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.shape: (100, 1058)\n",
            "\n",
            "train head:\n",
            "         ID  ExactMolWt  HeavyAtomCount  NumAtoms  NumValenceElectrons  \\\n",
            "0  TEST_000  415.247107            30.0      30.0                164.0   \n",
            "1  TEST_001  346.042923            21.0      21.0                108.0   \n",
            "2  TEST_002  417.115855            29.0      29.0                152.0   \n",
            "3  TEST_003  390.157102            27.0      27.0                144.0   \n",
            "4  TEST_004  459.068135            29.0      29.0                152.0   \n",
            "\n",
            "      MolMR  FractionCSP3  RingCount  NumAromaticRings  NumAliphaticRings  \\\n",
            "0  113.2879      0.695652        4.0               1.0                3.0   \n",
            "1   82.8520      0.266667        3.0               3.0                0.0   \n",
            "2  106.8959      0.200000        3.0               3.0                0.0   \n",
            "3  100.3857      0.500000        5.0               3.0                2.0   \n",
            "4  111.3915      0.318182        3.0               2.0                1.0   \n",
            "\n",
            "   ...  ecfp_fp_1014  ecfp_fp_1015  ecfp_fp_1016  ecfp_fp_1017  ecfp_fp_1018  \\\n",
            "0  ...             0             0             0             0             0   \n",
            "1  ...             0             0             0             0             0   \n",
            "2  ...             0             0             0             0             0   \n",
            "3  ...             0             0             0             0             0   \n",
            "4  ...             0             0             0             0             1   \n",
            "\n",
            "   ecfp_fp_1019  ecfp_fp_1020  ecfp_fp_1021  ecfp_fp_1022  ecfp_fp_1023  \n",
            "0             1             0             0             0             0  \n",
            "1             0             0             0             0             0  \n",
            "2             0             0             1             0             0  \n",
            "3             0             1             0             0             0  \n",
            "4             1             0             0             0             0  \n",
            "\n",
            "[5 rows x 1058 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/dacon_1/'\n",
        "output_filename = '03_1_test_new.csv'\n",
        "output_path = os.path.join(base_dir, output_filename)\n",
        "\n",
        "try:\n",
        "    test.to_csv(output_path, index=False)\n",
        "    print(f\"\\n'{output_filename}' 파일이 '{output_path}'에 성공적으로 저장되었습니다.\")\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"파일 존재 확인: {output_path}\")\n",
        "    else:\n",
        "        print(f\"오류: 파일 저장 후 존재 여부 확인 실패: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TXKFBdwPBQC",
        "outputId": "0556a187-7c54-47e7-9457-448edd6205e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'03_1_test_new.csv' 파일이 '/content/drive/MyDrive/dacon_1/03_1_test_new.csv'에 성공적으로 저장되었습니다.\n",
            "파일 존재 확인: /content/drive/MyDrive/dacon_1/03_1_test_new.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}